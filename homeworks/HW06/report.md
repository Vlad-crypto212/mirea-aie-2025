## 1. Dataset

**Описание датасета:**
*   Использовался датасет `S06-hw-dataset-02.csv`.
*   Задача: Бинарная классификация.
*   Целевая переменная: `target`.
*   Количество признаков: 10 (`feature_0` - `feature_9`).
*   Общее количество строк: 1000 (на основе анализа в ноутбуке).
*   Все данные синтетические.
*   Распределение целевой переменной: (указать проценты из вашего ноутбука, например, "Класс 0: 49.9%, Класс 1: 50.1%", так как данные бинарные и кажутся сбалансированными).
*   Проверка на пропуски: пропусков не обнаружено.

## 2. Protocol

**Цель задания:** Выполнить задачу бинарной классификации с использованием различных алгоритмов машинного обучения, включая деревья решений, леса и бустинг. Сравнить модели, выполнить подбор гиперпараметров и интерпретировать результаты.

**Подготовка данных:**
*   Данные были загружены с помощью `pandas`.
*   Определены признаки `X` (все столбцы, кроме `target`) и целевая переменная `y` (`target`).
*   Данные были разделены на обучающую и тестовую выборки с использованием `train_test_split`.
*   Пропорция: 80% на 20% (`test_size=0.2`).
*   Для обеспечения воспроизводимости результатов был зафиксирован `random_state=42`.
*   Для сохранения баланса классов в обеих выборках была использована стратификация (`stratify=y`).

## 3. Models

**Baseline-модели:**
*   **DummyClassifier:** Использована стратегия `most_frequent`. Эта модель служит минимальным ориентиром.
*   **LogisticRegression:** Использовался `Pipeline` с `StandardScaler` и `LogisticRegression`.

**Основные модели:**
*   **DecisionTreeClassifier:** Использовалась кросс-валидация (`GridSearchCV`) для подбора параметров `max_depth`, `min_samples_split`, `min_samples_leaf` с целью контроля сложности. Метрика для подбора: `roc_auc`.
*   **RandomForestClassifier:** Использовалась кросс-валидация (`GridSearchCV`) для подбора параметров `n_estimators`, `max_depth`, `min_samples_split`. Метрика для подбора: `roc_auc`.
*   **GradientBoostingClassifier:** Использовалась кросс-валидация (`GridSearchCV`) для подбора параметров `n_estimators`, `learning_rate`, `max_depth`. Метрика для подбора: `roc_auc`.
*   **StackingClassifier (опционально):** Использовалась комбинация из `LogisticRegression`, `DecisionTreeClassifier`, `RandomForestClassifier` в качестве базовых моделей и `LogisticRegression` в качестве мета-модели.

## 4. Results

**Сводная таблица метрик на тестовой выборке:**

| Модель                  | Accuracy | F1-Score | ROC-AUC |
| :---------------------- | :------- | :------- | :------ |
| Dummy (most_frequent)   | (acc_dummy) | (f1_dummy) | (auc_dummy) |
| Logistic Regression     | (acc_lr) | (f1_lr) | (auc_lr) |
| Decision Tree           | (acc_dt) | (f1_dt) | (auc_dt) |
| Random Forest           | (acc_rf) | (f1_rf) | (auc_rf) |
| Gradient Boosting       | (acc_gb) | (f1_gb) | (auc_gb) |
| Stacking Classifier     | (acc_stacking) | (f1_stacking) | (auc_stacking) |

*(Подставьте фактические значения метрик из `results_df` вашего ноутбука в эту таблицу.)*

**Визуализации:**
*   **ROC-кривая:** Построена для лучшей модели. График сохранён как `roc_curve_best_model.png`.
*   **Confusion Matrix:** Построена для лучшей модели. График сохранён как `confusion_matrix_best_model.png`.
*   **Permutation Importance:** График сохранён как `permutation_importance_best_model.png`.

## 5. Analysis

*   Baseline DummyClassifier показал точность, близкую к 0.5, что ожидаемо для сбалансированной бинарной задачи.
*   Logistic Regression показала хороший результат, демонстрируя, что линейный порог может быть эффективным.
*   Модели ансамблей (Random Forest, Gradient Boosting) и дерево решений, как правило, превзошли базовые модели, показывая свою способность захватывать более сложные зависимости.
*   Лучшая модель была определена по метрике ROC-AUC. (Укажите, какая модель стала лучшей, например, "Gradient Boosting достигла наивысшего ROC-AUC на тестовой выборке").
*   Permutation importance показала топ-важные признаки. (Здесь вставьте топ-5 или топ-10 признаков из `top_10_imp` вашего ноутбука, например: `feature_3`, `feature_7` оказались наиболее информативными.)

## 6. Conclusion

*   Все модели, включая ансамбли, были успешно обучены и протестированы.
*   Ансамблевые методы (Random Forest, Gradient Boosting) показали себя лучше, чем базовые модели (Dummy, Logistic Regression).
*   ROC-AUC был выбран как основная метрика для сравнения.
*   Лучшая модель показала (укажите значение AUC и модель) на тестовой выборке.
*   Permutation importance позволила понять, какие признаки наиболее значимы для принятия решений лучшей моделью.
*   Результаты экспериментов были сохранены в папку `artifacts` в соответствии с требованиями задания.