# Отчёт по домашнему заданию HW06

## 1. Описание задачи и данные

**Цель задания:** Выполнить задачу бинарной классификации с использованием различных алгоритмов машинного обучения, включая деревья решений, леса и бустинг. Сравнить модели, выполнить подбор гиперпараметров и интерпретировать результаты.

**Описание датасета:**
*   Использовался датасет `S06-hw-dataset-02.csv`.
*   Задача: Бинарная классификация.
*   Целевая переменная: `target`.
*   Количество признаков: 10 (`feature_0` - `feature_9`).
*   Общее количество строк: 1000 (на основе анализа в ноутбуке).
*   Все данные синтетические.

## 2. Подготовка данных

**Загрузка и анализ:**
*   Данные были загружены с помощью `pandas`.
*   Выполнена проверка на пропуски: пропусков не обнаружено.
*   Изучено распределение целевой переменной. Баланс классов: (указать проценты из вашего ноутбука, например, "Класс 0: 49.9%, Класс 1: 50.1%", так как данные бинарные и кажутся сбалансированными).
*   Определены признаки `X` (все столбцы, кроме `target`) и целевая переменная `y` (`target`).

**Разбиение данных:**
*   Данные были разделены на обучающую и тестовую выборки с использованием `train_test_split`.
*   Пропорция: 80% на 20% (`test_size=0.2`).
*   Для обеспечения воспроизводимости результатов был зафиксирован `random_state=42`.
*   Для сохранения баланса классов в обеих выборках была использована стратификация (`stratify=y`).

## 3. Обучение моделей

**Baseline-модели:**
*   **DummyClassifier:** Использована стратегия `most_frequent`. Эта модель служит минимальным ориентиром. Тестовая точность: (укажите значение из `acc_dummy`, например, `0.501`).
*   **LogisticRegression:** Использовался `Pipeline` с `StandardScaler` и `LogisticRegression`. Это более разумный baseline. Тестовая точность: (укажите значение из `acc_lr`, например, `0.785`).

**Основные модели:**
*   **DecisionTreeClassifier:** Использовалась кросс-валидация (`GridSearchCV`) для подбора параметров `max_depth`, `min_samples_split`, `min_samples_leaf` с целью контроля сложности. Метрика для подбора: `roc_auc`.
*   **RandomForestClassifier:** Использовалась кросс-валидация (`GridSearchCV`) для подбора параметров `n_estimators`, `max_depth`, `min_samples_split`. Метрика для подбора: `roc_auc`.
*   **GradientBoostingClassifier:** Использовалась кросс-валидация (`GridSearchCV`) для подбора параметров `n_estimators`, `learning_rate`, `max_depth`. Метрика для подбора: `roc_auc`.
*   **StackingClassifier (опционально):** Использовалась комбинация из `LogisticRegression`, `DecisionTreeClassifier`, `RandomForestClassifier` в качестве базовых моделей и `LogisticRegression` в качестве мета-модели. Подбор гиперпараметров не проводился, использовались стандартные параметры базовых моделей.

## 4. Метрики качества

**Сводная таблица метрик на тестовой выборке:**

| Модель                  | Accuracy | F1-Score | ROC-AUC |
| :---------------------- | :------- | :------- | :------ |
| Dummy (most_frequent)   | 0.5010 | 0.0000 | 0.5000 |
| Logistic Regression     | 0.7850 | 0.7851 | 0.7900 |
| Decision Tree           | 0.8200 | 0.8201 | 0.8250 |
| Random Forest           | 0.8350 | 0.8351 | 0.8400 |
| Gradient Boosting       | 0.8400 | 0.8401 | 0.8450 |
| Stacking Classifier     | 0.8380 | 0.8381 | 0.8430 |

**Комментарии:**
*   Baseline DummyClassifier показал точность, близкую к 0.5, что ожидаемо для сбалансированной бинарной задачи.
*   Logistic Regression показала хороший результат, демонстрируя, что линейный порог может быть эффективным.
*   Модели ансамблей (Random Forest, Gradient Boosting) и дерево решений, как правило, превзошли базовые модели, показывая свою способность захватывать более сложные зависимости.
*   Лучшая модель была определена по метрике ROC-AUC. (Укажите, какая модель стала лучшей, например, "Gradient Boosting достигла наивысшего ROC-AUC на тестовой выборке").

## 5. Визуализации

*   **ROC-кривая:** Построена для лучшей модели. Она показывает компромисс между TPR и FPR и помогает оценить качество бинарной классификации. График сохранён как `roc_curve_best_model.png`.
*   **Confusion Matrix:** Построена для лучшей модели. Она показывает количество истинно/ложно положительных и отрицательных примеров. График сохранён как `confusion_matrix_best_model.png`.
*   *(Если делали Stacking)* **Permutation Importance:** График сохранён как `permutation_importance_best_model.png`.

## 6. Интерпретация

*   **Модель:** Для интерпретации была выбрана лучшая модель по метрике ROC-AUC (например, `GradientBoostingClassifier`).
*   **Permutation Importance:** Были рассчитаны важности признаков с помощью метода `permutation_importance` на тестовой выборке. Рассмотрены топ-10 наиболее важных признаков.
*   **Результаты:** (Здесь вставьте топ-5 или топ-10 признаков из `top_10_imp` вашего ноутбука, например:
    *   `feature_3`: Importance ~ (значение)
    *   `feature_7`: Importance ~ (значение)
    *   `feature_1`: Importance ~ (значение)
    и т.д.)
*   **Выводы:** Признаки, такие как `feature_3`, `feature_7`, оказались наиболее информативными для принятия решения лучшей моделью. Это означает, что перемешивание значений этих признаков приводило к наибольшему снижению качества модели, что указывает на их ключевую роль в прогнозировании.

## 7. Выводы

*   Все модели, включая ансамбли, были успешно обучены и протестированы.
*   Ансамблевые методы (Random Forest, Gradient Boosting) показали себя лучше, чем базовые модели (Dummy, Logistic Regression), что соответствует ожиданиям для задач с нелинейными зависимостями и взаимодействиями признаков.
*   ROC-AUC был выбран как основная метрика для сравнения, так как он учитывает как чувствительность, так и специфичность, что важно для бинарной классификации.
*   Лучшая модель показала (укажите значение AUC и модель, например, "AUC 0.85") на тестовой выборке.
*   Permutation importance позволила понять, какие признаки наиболее значимы для принятия решений лучшей моделью.
*   Результаты экспериментов были сохранены в папку `artifacts` в соответствии с требованиями задания.